{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `uproot` can read ROOT objects from root type file without relying on ROOT I/O library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import json\n",
    "from io import StringIO\n",
    "\n",
    "def get_net_struct(obj_path):\n",
    "    '''\n",
    "    Directly read ROOT objects specified in obj_path.\n",
    "    obj_path -- file.root:Tdiectory/subdirectory/..../obj\n",
    "    \n",
    "    In this fuction we only need TString obj from the file.\n",
    "    '''\n",
    "    with uproot.open(File_path) as net_config:\n",
    "    #convert string to dictionary\n",
    "        assert (type(net_config) is uproot.models.TObjString.Model_TObjString )\n",
    "        _struct = json.load(StringIO(net_config))\n",
    "    return _struct\n",
    "\n",
    "def print_dimention(weights):\n",
    "    for w in weights[1:]:\n",
    "        print(w[\"weights\"])\n",
    "\n",
    "def all_layers(weights):\n",
    "    for i, w in enumerate(weights):\n",
    "        print(i, w.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#uproot.open(\"BTagCalibRUN2-08-40.root\").keys()\n",
    "\n",
    "Interested Dl1 networkes\n",
    "* 'DL1',\n",
    "* 'DL1/AntiKt4EMTopo',\n",
    "* 'DL1/AntiKt4EMTopo/net_configuration',\n",
    "* 'DL1mu',\n",
    "* 'DL1mu/AntiKt4EMTopo',\n",
    "* 'DL1mu/AntiKt4EMTopo/net_configuration',\n",
    "* 'DL1rnn',\n",
    "* 'DL1rnn/AntiKt4EMTopo',\n",
    "* 'DL1rnn/AntiKt4EMTopo/net_configuration',\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL1rnn \n",
    "DL1rnn is a neural network trained by b-tagging group. \n",
    "Model weights are stored in `BTagCalibRUN2-08-40.root` file as a string object. Our goal is to read the weight strings and convert them into json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of layers: 17\n",
      "0 dict_keys(['sublayers', 'activation', 'architecture'])\n",
      "1 dict_keys(['bias', 'weights', 'architecture'])\n",
      "2 dict_keys(['bias', 'weights', 'activation', 'architecture'])\n",
      "3 dict_keys(['bias', 'weights', 'architecture'])\n",
      "4 dict_keys(['bias', 'weights', 'activation', 'architecture'])\n",
      "5 dict_keys(['bias', 'weights', 'architecture'])\n",
      "6 dict_keys(['bias', 'weights', 'activation', 'architecture'])\n",
      "7 dict_keys(['bias', 'weights', 'architecture'])\n",
      "8 dict_keys(['bias', 'weights', 'activation', 'architecture'])\n",
      "9 dict_keys(['bias', 'weights', 'architecture'])\n",
      "10 dict_keys(['sublayers', 'activation', 'architecture'])\n",
      "11 dict_keys(['bias', 'weights', 'architecture'])\n",
      "12 dict_keys(['bias', 'weights', 'activation', 'architecture'])\n",
      "13 dict_keys(['bias', 'weights', 'architecture'])\n",
      "14 dict_keys(['bias', 'weights', 'activation', 'architecture'])\n",
      "15 dict_keys(['bias', 'weights', 'architecture'])\n",
      "16 dict_keys(['bias', 'weights', 'activation', 'architecture'])\n"
     ]
    }
   ],
   "source": [
    "#filename.root:Tdirectory/directory/obj\n",
    "File_path=\"BTagCalibRUN2-08-40.root:DL1/AntiKt4EMTopo/net_configuration\"\n",
    "\n",
    "DL1_struct = get_net_struct(File_path)\n",
    "DL1_weights = DL1_struct['layers']\n",
    "\n",
    "print(f\"number of layers: {len(DL1_weights)}\")\n",
    "all_layers(DL1_weights)\n",
    "#print_dimention(weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sublayers` stored weights and biases of MaxoutDense layers.  Total of two MaxoutDense leyers are stored.  \n",
    "Other layers are BatchNoramlization and Dense layers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['layers', 'outputs', 'defaults', 'inputs'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DL1_struct.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#DL1_weights[0]['sublayers'][maxout_unit]['bias']\n",
    "\n",
    "def get_maxout_weights(NN_layer):\n",
    "    maxout_unit=0\n",
    "    maxout_h_unit=len(NN_layer['sublayers'][maxout_unit]['bias'])\n",
    "    in_features = len(NN_layer['sublayers'][maxout_unit]['weights'])//maxout_h_unit\n",
    "    weight = np.array(NN_layer['sublayers'][maxout_unit]['weights']).reshape(in_features, maxout_h_unit)\n",
    "    maxout_weights=[]\n",
    "    maxout_biases = []\n",
    "\n",
    "    for maxout_unit in range(25):\n",
    "        maxout_weights.append(\n",
    "                                np.array(NN_layer['sublayers'][maxout_unit]['weights']\n",
    "                              ).reshape(in_features, maxout_h_unit) )\n",
    "        maxout_biases.append(\n",
    "                                np.array(NN_layer['sublayers'][maxout_unit]['bias'])\n",
    "                            )\n",
    "    return (np.concatenate(maxout_weights, axis=1), np.array( maxout_biases).flatten())\n",
    "\n",
    "def get_dense_weights(NN_layer):\n",
    "    h_unit=len(NN_layer[\"bias\"])\n",
    "    in_features = len(NN_layer['weights'])//h_unit\n",
    "    weight = np.array(NN_layer['weights']).reshape(in_features, h_unit)\n",
    "    return (weight, np.array(NN_layer[\"bias\"]) )\n",
    "\n",
    "def get_BN_weights(NN_layer):\n",
    "    h_unit=len(NN_layer[\"bias\"])\n",
    "    return (np.array(NN_layer['weights']),\n",
    "            np.array(NN_layer[\"bias\"]), \n",
    "            np.array(h_unit*[0]), np.array(h_unit*[1]) ) \n",
    "             \n",
    "maxout_w, maxout_b = get_maxout_weights(DL1_weights[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.35040843e+00, -1.66020200e-01, -1.97673023e+00],\n",
       "        [-5.76982737e-01,  1.77271590e-01,  5.48534654e-02],\n",
       "        [ 6.44354999e-01, -3.26688260e-01,  4.08351779e-01],\n",
       "        [ 2.89725870e-01, -2.53850769e-04, -1.28739476e-01],\n",
       "        [ 1.25599802e+00, -9.43711817e-01,  1.12691796e+00],\n",
       "        [-8.74396861e-02, -6.20727062e-01, -8.17855239e-01]]),\n",
       " array([-0.58612728,  0.66026765, -0.19757801]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(DL1_weights[10]['sublayers'][maxout_unit]['weights'])//24\n",
    "get_dense_weights(DL1_weights[16])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the bellow, I defin DL1rnn with tensorflow keras API. Instead of train the new network, I will set weights of each layer to the weights extracted above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_addons as tfa\n",
    "#from keras.layers.core import MaxoutDense\n",
    "\n",
    "from models.maxout_layers import Maxout1D\n",
    "    \n",
    "DL1_layers = [ 72, 57, 60, 48, 36,24, 12, 6]\n",
    "DL1_dropouts = [0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "dropout_enable = True\n",
    "\n",
    "# DL1rnn definition\n",
    "#maxoutdense1 = MaxoutDense1D(72, 25)\n",
    "#maxoutdense6 = MaxoutDense1D(24, 25)\n",
    "def get_DL1(N_features, h_layers, lr=0.01, drops=None):\n",
    "    In = tf.keras.layers.Input(shape=(N_features,))\n",
    "    x = In\n",
    "    x = Maxout1D(h_layers[0], 25)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    if drops:\n",
    "            x = keras.layers.Dropout(drops[0])(x, training=True)\n",
    "            \n",
    "    for i, h in enumerate(h_layers[1:]):\n",
    "        if i ==4:\n",
    "            x = Maxout1D(h, 25)(x)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            if drops: x = keras.layers.Dropout(drops[i+1])(x, training=True)\n",
    "            continue\n",
    "            \n",
    "        x = keras.layers.Dense(h, activation=\"linear\",\n",
    "                  kernel_initializer='glorot_uniform')(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.Activation(\"relu\")(x)\n",
    "        \n",
    "        if drops:\n",
    "            x = keras.layers.Dropout(drops[i+1])(x, training=True)\n",
    "            \n",
    "    predictions = keras.layers.Dense(3, activation='softmax',\n",
    "                        kernel_initializer='glorot_uniform')(x)\n",
    "\n",
    "    model = keras.models.Model(inputs=In, outputs=predictions)\n",
    "\n",
    "    model_optimizer = keras.optimizers.Adam(lr=lr)\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "        optimizer=model_optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 41)]              0         \n",
      "_________________________________________________________________\n",
      "maxout1d (Maxout1D)          (None, 72)                75600     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 72)                288       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 57)                4161      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 57)                228       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 57)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 57)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                3480      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 48)                2928      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 48)                192       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 36)                1764      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "maxout1d_1 (Maxout1D)        (None, 24)                22200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 24)                96        \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 12)                48        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 111,792\n",
      "Trainable params: 111,162\n",
      "Non-trainable params: 630\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DL1_model = get_DL1(41,DL1_layers, drops=DL1_dropouts if dropout_enable else None )\n",
    "DL1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "4 2\n",
      "8 4\n",
      "12 6\n",
      "16 8\n",
      "20 10\n",
      "23 12\n",
      "27 14\n",
      "31 16\n"
     ]
    }
   ],
   "source": [
    "#index=0 is input layer\n",
    "\n",
    "k=-2 # layer index for weights from the root file\n",
    "\n",
    "layer_index = {True: [1,4,8,12, 16, 20, 23, 27, 31],#1,20 are maxout\n",
    "              False: [1,3,6,9,12,15,17,20, 23] #1,15 are maxout\n",
    "              } \n",
    "maxout_index = {True: [1, 20],\n",
    "               False: [1, 15]}\n",
    "\n",
    "for i in layer_index[dropout_enable]:\n",
    "    k = k+2\n",
    "    print(i, k)\n",
    "    if i in maxout_index[dropout_enable]:\n",
    "        maxout_L = DL1_model.get_layer( index=i)\n",
    "        maxout_L.set_weights(get_maxout_weights(DL1_weights[k]))\n",
    "        BN_L = DL1_model.get_layer( index=i+1)\n",
    "        BN_L.set_weights(get_BN_weights(DL1_weights[k+1]))\n",
    "        continue\n",
    "    if i == layer_index[dropout_enable][-1]:\n",
    "        Dense_L = DL1_model.get_layer( index=i)\n",
    "        Dense_L.set_weights(get_dense_weights(DL1_weights[k]))\n",
    "        continue\n",
    "    Dense_L = DL1_model.get_layer( index=i)\n",
    "    Dense_L.set_weights(get_dense_weights(DL1_weights[k]))\n",
    "    BN_L = DL1_model.get_layer( index=i+1)\n",
    "    BN_L.set_weights(get_BN_weights(DL1_weights[k+1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[0.1679932 , 0.58424383, 0.24776304],\n",
       "       [0.18530111, 0.57879996, 0.23589899],\n",
       "       [0.1679932 , 0.58424383, 0.24776304],\n",
       "       [0.1679932 , 0.58424383, 0.24776304],\n",
       "       [0.1679932 , 0.58424383, 0.24776304]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test model with dummy inputs\n",
    "DL1_model(inputs=np.random.random((5, 41)), training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DL1_AntiKt4EMTopo_dropout/assets\n"
     ]
    }
   ],
   "source": [
    "model_file = \"DL1_AntiKt4EMTopo_dropout\" if dropout_enable else \"DL1_AntiKt4EMTopo\"\n",
    "DL1_model.save(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save this model\n",
    "\n",
    "This model contains a custom layer which can not be saved as a single `.h5` file with `save(\"model.h5\")`. Becuase, the custom layer implemented in the model is not know, and you will get an error when loading the model again.   \n",
    "Alternatively, `save(\"DL1_AntiKt4EMTopo\")` will save our model into a directory which contains model architecture and weights.\n",
    "\n",
    "## Load model\n",
    "\n",
    "load_model() fuction `tf.keras.models.load_model(\"DL1_AntiKt4EMTopo\")` can directly load model architectures and weights including the custom layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 41)]              0         \n",
      "_________________________________________________________________\n",
      "maxout1d (Maxout1D)          (None, 72)                75600     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 72)                288       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 57)                4161      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 57)                228       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 57)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 57)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                3480      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 48)                2928      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 48)                192       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 36)                1764      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "maxout1d_1 (Maxout1D)        (None, 24)                22200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 24)                96        \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 12)                48        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 111,792\n",
      "Trainable params: 111,162\n",
      "Non-trainable params: 630\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_model = tf.keras.models.load_model(model_file)\n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[9.9961275e-01, 3.8171333e-04, 5.5667260e-06],\n",
       "       [7.6519459e-01, 2.0181756e-01, 3.2987844e-02],\n",
       "       [7.6483935e-01, 2.0210320e-01, 3.3057477e-02],\n",
       "       [3.0023044e-01, 5.2644479e-01, 1.7332473e-01],\n",
       "       [1.6799320e-01, 5.8424383e-01, 2.4776304e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(inputs=np.random.random((5, 41)), training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
