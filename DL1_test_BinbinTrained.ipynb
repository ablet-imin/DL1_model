{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['X_test', 'X_trk_test', 'Y_test', 'labels', 'pt_eta']>\n",
      "Total number of events:  1928080\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def DL1_score(pb, pc, pl): \n",
    "    return np.log(pb/(0.018*pc + 0.982*pl))\n",
    "\n",
    "def plot_prob_score(pb, pc, pl):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    _n, bins, _ = ax1.hist(pb, bins=50, range=(0,1), alpha=0.5, label=\"p_b\")\n",
    "    _ = ax1.hist(pc, bins=bins, alpha=0.5, label=\"p_c\")\n",
    "    _ = ax1.hist(pl, bins=bins, alpha=0.5, label=\"p_l\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    \n",
    "    _ =ax2.hist(DL1_socre(pb, pc, pl), 100, alpha=0.6)\n",
    "\n",
    "def plot_prob_score_from_model(event, model):\n",
    "    \n",
    "    Single_Pred_prob = model(np.array(10000*[X_test[event,:]]))\n",
    "    pb = Single_Pred_prob[:,2].numpy()\n",
    "    pc = Single_Pred_prob[:,1].numpy()\n",
    "    pl = Single_Pred_prob[:,0].numpy()\n",
    "    print(\"true label: \", Y_test[event])\n",
    "    print(\"softmax prob: \", Single_Pred_prob[event])\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    _n, bins, _ = ax1.hist(pb, bins=50, range=(0,1),  alpha=0.5, label=\"p_b\")\n",
    "    _ = ax1.hist(pc, bins=bins,  alpha=0.5, label=\"p_c\")\n",
    "    _ = ax1.hist(pl, bins=bins,  alpha=0.5, label=\"p_l\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    \n",
    "    _ =ax2.hist(DL1_socre(pb, pc, pl), 100,  alpha=0.6)\n",
    "\n",
    "def efficiency(score, wp=1.0):\n",
    "    return np.sum(score>wp)/len(score)\n",
    "    \n",
    "    \n",
    "hf = h5py.File(\"/Users/abletimin/cernbox/b-tagg/btagging-ml_tutorial_files/MC16d_ttbar-test-validation_sample-NN.h5\", 'r')\n",
    "print(hf.keys())\n",
    "X_test, Y_test = hf['X_test'][:], hf['Y_test'][:]\n",
    "hf.close() \n",
    "print(\"Total number of events: \",len(X_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 78)                3510      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 78)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 78)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 78)                312       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 66)                5214      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 66)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 66)                264       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 57)                3819      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 57)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 57)                228       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 48)                2784      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 48)                192       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 36)                1764      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 24)                888       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 24)                96        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 12)                48        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 19,686\n",
      "Trainable params: 19,032\n",
      "Non-trainable params: 654\n",
      "_________________________________________________________________\n",
      "Acc:  0.8002941\n",
      "bjet Acc:  0.80029327\n",
      "cjet Acc:  0.80029285\n",
      "ljet Acc:  0.80029285\n"
     ]
    }
   ],
   "source": [
    "DL1_model = tf.keras.models.load_model(\"/Users/abletimin/cernbox/b-tagg/trainedModel/DL1r_2M_300epoch_3600batch.h5\")\n",
    "DL1_model.summary()\n",
    "\n",
    "Pred_prob = DL1_model(X_test)\n",
    "\n",
    "#print(\"true label: \", Y_test[event])\n",
    "acc = tf.keras.metrics.CategoricalAccuracy()\n",
    "acc.update_state(Y_test, Pred_prob.numpy())\n",
    "print (\"Acc: \", acc.result().numpy())\n",
    "\n",
    "acc.update_state(Y_test[:,2], Pred_prob[:2])\n",
    "print (\"bjet Acc: \", acc.result().numpy())\n",
    "acc.update_state(Y_test[:,1], Pred_prob[:1])\n",
    "print (\"cjet Acc: \", acc.result().numpy())\n",
    "acc.update_state(Y_test[:,0], Pred_prob[:0])\n",
    "print (\"ljet Acc: \", acc.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7978849744952022"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred_prob_pb = Pred_prob[Y_test[:,2]==1]\n",
    "efficiency( DL1_score(Pred_prob_pb[:,2], Pred_prob_pb[:,1], Pred_prob_pb[:,0]), 1.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(750251,), dtype=float32, numpy=\n",
       "array([0.9958332 , 0.37944305, 0.24621114, ..., 0.19877161, 0.7958348 ,\n",
       "       0.12091827], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred_prob_pb[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-27db51e43769>:1: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  hfile = h5py.File(\"/Users/abletimin/cernbox/b-tagg/trainedModel/DL1r_2M_300epoch_3600batch.h5\")\n"
     ]
    }
   ],
   "source": [
    "hfile = h5py.File(\"/Users/abletimin/cernbox/b-tagg/trainedModel/DL1r_2M_300epoch_3600batch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['activation', 'batch_normalization', 'batch_normalization_1', 'batch_normalization_2', 'batch_normalization_3', 'batch_normalization_4', 'batch_normalization_5', 'batch_normalization_6', 'batch_normalization_7', 'dense', 'dense_1', 'dense_2', 'dense_3', 'dense_4', 'dense_5', 'dense_6', 'dense_7', 'dense_8', 'dropout', 'dropout_1', 'dropout_2', 'dropout_3', 'dropout_4', 'dropout_5', 'dropout_6', 'dropout_7']>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfile[\"model_weights\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
